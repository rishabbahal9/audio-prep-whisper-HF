# Preparing data for whisper training & HF's audio datasets

## Introduction
This repository will help you prepare audio chunks with transcripts in parquet format that can be used to fine tune 
whisper model by open ai.

## Instructions
### Step 1: Clone the repository
```bash
git clone <repository_link>
```

### Step 2: Install the required packages
```bash
pip install -r requirements.txt
```

### Step 3: Download the video
Download the video you want to extract audio from in mp4 format. I use yt1d.com to download youtube videos.

### Step 4: Extract audio from the video in .wav format
```bash
ffmpeg -i video.mp4 -q:a 0 -map a audio.wav
```
### Step 5: Make sure audio is in the right format (mono-channel, 16 kHz)
```bash
ffmpeg -i audio.wav -ac 1 -ar 16000 audio_16khz.wav
```

### Step 6: Split the audio into chunks
By default, I am doing 10 seconds chunks. You can change the duration by changing the value of "segment_time" in the 
command below. If you do so, make sure you change the value of **chunk_duration** in the file **transcribe_audio.py** 
as well.
```bash
mkdir audio # create "audio" directory
ffmpeg -i audio_16khz.wav -f segment -segment_time 30 -c copy audio/output_%03d.wav
```
### step 7: Prepare python environment
```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
```
Install the required packages
```bash
pip install -r requirements.txt
```
Login into hugging face. Generate token from https://huggingface.co/settings/tokens
```bash
huggingface-cli login
```

### Step 8: Transcribe the audio chunks, using whisper model
Before running this command make sure you have correct value of **chunk_duration** in **transcribe_audio.py** file as 
per step 6.
```bash
python transcribe_audio.py
```
This will create a file named **data.json** in the *root* directory.

### Step 9: Correct the transcripts in data.json file
You need to manually check and correct the transcript generated by the default whisper model. Make the corrections 
and save.

### Step 10: Generate parquet file from data.json
In this step, data.json is taken and audio_data is converted in raw bytes and audio.parquet is created in data 
directory.
```bash
python generate_parquet.py
```
You can confirm if the file is in right format by running the following command
```bash
python read_parquet.py
```

### Step 11: Upload the parquet file to hugging face
Before running the command, give a proper name to dataset in **upload_parquet.py** file (Last line).
```bash
python upload_parquet.py
```